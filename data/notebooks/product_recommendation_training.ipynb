{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a49c9f",
   "metadata": {},
   "source": [
    "Install and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b007271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need packages (run once in a notebook cell). Uncomment to install.\n",
    "# !pip install xgboost joblib tensorflow scikit-learn\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Try import xgboost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception as e:\n",
    "    print(\"xgboost not available; XGBoost model will be skipped. Install with `pip install xgboost` if desired.\")\n",
    "    HAS_XGB = False\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5959f9",
   "metadata": {},
   "source": [
    "Paths and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae6290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:/Users/awini/formative2-mlp/data/processed/merged_customer_data.csv\n",
      "Shape: (117, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_new</th>\n",
       "      <th>social_media_platform</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>purchase_interest_score</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>customer_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>Twitter,Instagram</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Negative,Neutral</td>\n",
       "      <td>1113</td>\n",
       "      <td>172</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>Twitter,Instagram</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Negative,Neutral</td>\n",
       "      <td>1147</td>\n",
       "      <td>387</td>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1017</td>\n",
       "      <td>271</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>Books</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1021</td>\n",
       "      <td>192</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1059</td>\n",
       "      <td>408</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>Books</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id_new social_media_platform  engagement_score  \\\n",
       "0              100     Twitter,Instagram              77.0   \n",
       "1              100     Twitter,Instagram              77.0   \n",
       "2              101               Twitter              68.0   \n",
       "3              101               Twitter              68.0   \n",
       "4              101               Twitter              68.0   \n",
       "\n",
       "   purchase_interest_score  review_sentiment  transaction_id  purchase_amount  \\\n",
       "0                      4.4  Negative,Neutral            1113              172   \n",
       "1                      4.4  Negative,Neutral            1147              387   \n",
       "2                      1.0           Neutral            1017              271   \n",
       "3                      1.0           Neutral            1021              192   \n",
       "4                      1.0           Neutral            1059              408   \n",
       "\n",
       "  purchase_date product_category  customer_rating  \n",
       "0    2024-04-22         Clothing              4.0  \n",
       "1    2024-05-26            Books              4.6  \n",
       "2    2024-01-17            Books              2.1  \n",
       "3    2024-01-21        Groceries              3.4  \n",
       "4    2024-02-28            Books              2.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117 entries, 0 to 116\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   customer_id_new          117 non-null    int64  \n",
      " 1   social_media_platform    117 non-null    object \n",
      " 2   engagement_score         117 non-null    float64\n",
      " 3   purchase_interest_score  117 non-null    float64\n",
      " 4   review_sentiment         117 non-null    object \n",
      " 5   transaction_id           117 non-null    int64  \n",
      " 6   purchase_amount          117 non-null    int64  \n",
      " 7   purchase_date            117 non-null    object \n",
      " 8   product_category         117 non-null    object \n",
      " 9   customer_rating          117 non-null    float64\n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 9.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Paths (change if your repo path differs)\n",
    "DATA_FP = \"C:/Users/awini/formative2-mlp/data/processed/merged_customer_data.csv\"\n",
    "MODELS_DIR = \"C:/Users/awini/formative2-mlp/data/processed/models\"\n",
    "Path(MODELS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATA_FP)\n",
    "print(\"Loaded:\", DATA_FP)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf808237",
   "metadata": {},
   "source": [
    "Quick cleaning & choose target/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2be2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['engagement_score', 'purchase_interest_score', 'purchase_amount', 'customer_rating']\n",
      "Categorical features: ['social_media_platform', 'review_sentiment']\n",
      "After cleaning, sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>purchase_interest_score</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>primary_platform</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Negative,Neutral</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>387</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Negative,Neutral</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>271</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>408</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engagement_score  purchase_interest_score  purchase_amount  \\\n",
       "0              77.0                      4.4              172   \n",
       "1              77.0                      4.4              387   \n",
       "2              68.0                      1.0              271   \n",
       "3              68.0                      1.0              192   \n",
       "4              68.0                      1.0              408   \n",
       "\n",
       "   customer_rating  review_sentiment primary_platform product_category  \n",
       "0              4.0  Negative,Neutral          Twitter         Clothing  \n",
       "1              4.6  Negative,Neutral          Twitter            Books  \n",
       "2              2.1           Neutral          Twitter            Books  \n",
       "3              3.4           Neutral          Twitter        Groceries  \n",
       "4              2.5           Neutral          Twitter            Books  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target\n",
    "target_col = \"product_category\"\n",
    "assert target_col in df.columns, f\"Target column '{target_col}' not found.\"\n",
    "\n",
    "# Drop rows without target\n",
    "df = df.dropna(subset=[target_col]).copy()\n",
    "\n",
    "# Candidate numeric and categorical features — adjust if columns differ\n",
    "numeric_cols = [c for c in ['engagement_score', 'purchase_interest_score', 'purchase_amount', 'customer_rating'] if c in df.columns]\n",
    "categorical_cols = [c for c in ['social_media_platform', 'review_sentiment'] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", numeric_cols)\n",
    "print(\"Categorical features:\", categorical_cols)\n",
    "\n",
    "# If social_media_platform has combined values like \"Twitter,Instagram\", simplify to primary platform\n",
    "if 'social_media_platform' in df.columns:\n",
    "    df['primary_platform'] = df['social_media_platform'].astype(str).str.split(',').str[0].fillna('unknown')\n",
    "    if 'primary_platform' not in categorical_cols:\n",
    "        categorical_cols.append('primary_platform')\n",
    "    if 'social_media_platform' in categorical_cols:\n",
    "        categorical_cols.remove('social_media_platform')\n",
    "\n",
    "# Fill missing numeric with median\n",
    "for c in numeric_cols:\n",
    "    if df[c].isna().sum() > 0:\n",
    "        df[c].fillna(df[c].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical with 'unknown'\n",
    "for c in categorical_cols:\n",
    "    df[c] = df[c].fillna('unknown')\n",
    "\n",
    "print(\"After cleaning, sample:\")\n",
    "display(df[numeric_cols + categorical_cols + [target_col]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2d50b",
   "metadata": {},
   "source": [
    "Build preprocessing pipeline and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5930eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (93, 6) Test shape: (24, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One-hot encode categorical, scale numeric\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[numeric_cols + categorical_cols]\n",
    "y = df[target_col].astype(str)\n",
    "\n",
    "# Train/test split (stratify to keep class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b522c",
   "metadata": {},
   "source": [
    "Helper: evaluate & save utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee833828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1 (macro):\", f1m)\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return {'name': name, 'accuracy': acc, 'f1_macro': f1m}\n",
    "\n",
    "def save_sklearn_model(model, out_fp):\n",
    "    joblib.dump(model, out_fp)\n",
    "    print(\"Saved sklearn model to:\", out_fp)\n",
    "\n",
    "def save_keras_model(keras_model, out_fp):\n",
    "    # Keras model saved in the TensorFlow SavedModel or .keras format\n",
    "    keras_model.save(out_fp)\n",
    "    print(\"Saved Keras model to:\", out_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dc319",
   "metadata": {},
   "source": [
    "Train Random Forest (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "278452cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest ---\n",
      "Accuracy: 0.16666666666666666\n",
      "F1 (macro): 0.12571428571428572\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Books       0.00      0.00      0.00         4\n",
      "    Clothing       0.17      0.25      0.20         4\n",
      " Electronics       0.38      0.50      0.43         6\n",
      "   Groceries       0.00      0.00      0.00         4\n",
      "      Sports       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.17        24\n",
      "   macro avg       0.11      0.15      0.13        24\n",
      "weighted avg       0.12      0.17      0.14        24\n",
      "\n",
      "Saved sklearn model to: C:/Users/awini/formative2-mlp/data/processed/models\\product_recommender_rf.joblib\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_res = evaluate_model(\"Random Forest\", rf_pipeline, X_test, y_test)\n",
    "# save\n",
    "rf_fp = os.path.join(MODELS_DIR, \"product_recommender_rf.joblib\")\n",
    "save_sklearn_model(rf_pipeline, rf_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878756c6",
   "metadata": {},
   "source": [
    "Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40a011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Accuracy: 0.20833333333333334\n",
      "F1 (macro): 0.19653679653679654\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Books       0.00      0.00      0.00         4\n",
      "    Clothing       0.29      0.50      0.36         4\n",
      " Electronics       0.33      0.33      0.33         6\n",
      "   Groceries       0.33      0.25      0.29         4\n",
      "      Sports       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.21        24\n",
      "   macro avg       0.19      0.22      0.20        24\n",
      "weighted avg       0.19      0.21      0.19        24\n",
      "\n",
      "Saved sklearn model to: C:/Users/awini/formative2-mlp/data/processed/models\\product_recommender_lr.joblib\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1))\n",
    "])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_res = evaluate_model(\"Logistic Regression\", lr_pipeline, X_test, y_test)\n",
    "lr_fp = os.path.join(MODELS_DIR, \"product_recommender_lr.joblib\")\n",
    "save_sklearn_model(lr_pipeline, lr_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a72f79",
   "metadata": {},
   "source": [
    "Train XGBoost (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c4bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost ---\n",
      "Accuracy: 0.25\n",
      "F1 (macro): 0.2188888888888889\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.20      0.25      0.22         4\n",
      "           2       0.33      0.50      0.40         6\n",
      "           3       0.25      0.25      0.25         4\n",
      "           4       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.25        24\n",
      "   macro avg       0.22      0.23      0.22        24\n",
      "weighted avg       0.24      0.25      0.23        24\n",
      "\n",
      "Saved sklearn model to: C:/Users/awini/formative2-mlp/data/processed/models\\product_recommender_xgb.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awini\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [12:13:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Now fit the pipeline\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train_enc)\n",
    "\n",
    "# Evaluate\n",
    "xgb_res = evaluate_model(\"XGBoost\", xgb_pipeline, X_test, y_test_enc)\n",
    "\n",
    "# Save model\n",
    "xgb_fp = os.path.join(MODELS_DIR, \"product_recommender_xgb.joblib\")\n",
    "save_sklearn_model(xgb_pipeline, xgb_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad6d43",
   "metadata": {},
   "source": [
    "Prepare data for Keras (dense NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d35b10fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessor to get numpy arrays (fit already on training pipelines above)\n",
    "preprocessor.fit(X_train)  # ensure fitted\n",
    "X_train_pre = preprocessor.transform(X_train)\n",
    "X_test_pre = preprocessor.transform(X_test)\n",
    "\n",
    "# Encode target labels to integers for Keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a9a5e",
   "metadata": {},
   "source": [
    "Build, train, and save Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "343ee5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(1.1625), 1: np.float64(1.0333333333333334), 2: np.float64(0.8857142857142857), 3: np.float64(1.1625), 4: np.float64(0.8454545454545455)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m5,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,917</span> (152.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,917\u001b[0m (152.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,917</span> (152.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,917\u001b[0m (152.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 - 2s - 589ms/step - accuracy: 0.1807 - loss: 1.6397 - val_accuracy: 0.1000 - val_loss: 1.6838\n",
      "Epoch 2/30\n",
      "3/3 - 0s - 67ms/step - accuracy: 0.3012 - loss: 1.5977 - val_accuracy: 0.2000 - val_loss: 1.6579\n",
      "Epoch 3/30\n",
      "3/3 - 0s - 40ms/step - accuracy: 0.2892 - loss: 1.5412 - val_accuracy: 0.3000 - val_loss: 1.6467\n",
      "Epoch 4/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.3133 - loss: 1.5098 - val_accuracy: 0.3000 - val_loss: 1.6386\n",
      "Epoch 5/30\n",
      "3/3 - 0s - 65ms/step - accuracy: 0.4096 - loss: 1.4894 - val_accuracy: 0.2000 - val_loss: 1.6367\n",
      "Epoch 6/30\n",
      "3/3 - 0s - 57ms/step - accuracy: 0.3976 - loss: 1.4691 - val_accuracy: 0.2000 - val_loss: 1.6343\n",
      "Epoch 7/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.4458 - loss: 1.4278 - val_accuracy: 0.2000 - val_loss: 1.6256\n",
      "Epoch 8/30\n",
      "3/3 - 0s - 35ms/step - accuracy: 0.5060 - loss: 1.4081 - val_accuracy: 0.3000 - val_loss: 1.6246\n",
      "Epoch 9/30\n",
      "3/3 - 0s - 38ms/step - accuracy: 0.4458 - loss: 1.3989 - val_accuracy: 0.3000 - val_loss: 1.6294\n",
      "Epoch 10/30\n",
      "3/3 - 0s - 44ms/step - accuracy: 0.5181 - loss: 1.3552 - val_accuracy: 0.3000 - val_loss: 1.6217\n",
      "Epoch 11/30\n",
      "3/3 - 0s - 60ms/step - accuracy: 0.5422 - loss: 1.3118 - val_accuracy: 0.3000 - val_loss: 1.6144\n",
      "Epoch 12/30\n",
      "3/3 - 0s - 40ms/step - accuracy: 0.5783 - loss: 1.3053 - val_accuracy: 0.3000 - val_loss: 1.6088\n",
      "Epoch 13/30\n",
      "3/3 - 0s - 41ms/step - accuracy: 0.5422 - loss: 1.2711 - val_accuracy: 0.3000 - val_loss: 1.6016\n",
      "Epoch 14/30\n",
      "3/3 - 0s - 54ms/step - accuracy: 0.5783 - loss: 1.2563 - val_accuracy: 0.3000 - val_loss: 1.5978\n",
      "Epoch 15/30\n",
      "3/3 - 0s - 38ms/step - accuracy: 0.6024 - loss: 1.2313 - val_accuracy: 0.3000 - val_loss: 1.5891\n",
      "Epoch 16/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.6747 - loss: 1.1597 - val_accuracy: 0.3000 - val_loss: 1.5904\n",
      "Epoch 17/30\n",
      "3/3 - 0s - 47ms/step - accuracy: 0.6386 - loss: 1.1556 - val_accuracy: 0.3000 - val_loss: 1.5987\n",
      "Epoch 18/30\n",
      "3/3 - 0s - 43ms/step - accuracy: 0.6265 - loss: 1.1399 - val_accuracy: 0.3000 - val_loss: 1.6083\n",
      "Epoch 19/30\n",
      "3/3 - 0s - 41ms/step - accuracy: 0.6024 - loss: 1.1120 - val_accuracy: 0.3000 - val_loss: 1.6114\n",
      "Epoch 20/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.6867 - loss: 1.0882 - val_accuracy: 0.3000 - val_loss: 1.6178\n",
      "Epoch 21/30\n",
      "3/3 - 0s - 39ms/step - accuracy: 0.6747 - loss: 1.0539 - val_accuracy: 0.3000 - val_loss: 1.6141\n",
      "Epoch 22/30\n",
      "3/3 - 0s - 39ms/step - accuracy: 0.6627 - loss: 1.0354 - val_accuracy: 0.3000 - val_loss: 1.6181\n",
      "Epoch 23/30\n",
      "3/3 - 0s - 38ms/step - accuracy: 0.6988 - loss: 1.0245 - val_accuracy: 0.3000 - val_loss: 1.6249\n",
      "Epoch 24/30\n",
      "3/3 - 0s - 41ms/step - accuracy: 0.6747 - loss: 0.9912 - val_accuracy: 0.3000 - val_loss: 1.6406\n",
      "Epoch 25/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.6988 - loss: 0.9320 - val_accuracy: 0.3000 - val_loss: 1.6558\n",
      "Epoch 26/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.6988 - loss: 0.9374 - val_accuracy: 0.3000 - val_loss: 1.6704\n",
      "Epoch 27/30\n",
      "3/3 - 0s - 38ms/step - accuracy: 0.7349 - loss: 0.9150 - val_accuracy: 0.3000 - val_loss: 1.6998\n",
      "Epoch 28/30\n",
      "3/3 - 0s - 37ms/step - accuracy: 0.7590 - loss: 0.8855 - val_accuracy: 0.2000 - val_loss: 1.7173\n",
      "Epoch 29/30\n",
      "3/3 - 0s - 38ms/step - accuracy: 0.6627 - loss: 0.9027 - val_accuracy: 0.2000 - val_loss: 1.7585\n",
      "Epoch 30/30\n",
      "3/3 - 0s - 39ms/step - accuracy: 0.7590 - loss: 0.8504 - val_accuracy: 0.2000 - val_loss: 1.7846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Keras Test Accuracy: 0.125\n",
      "Keras Test F1 (macro): 0.10666666666666666\n",
      "Saved Keras model to: C:/Users/awini/formative2-mlp/data/processed/models\\product_recommender_keras.keras\n",
      "Saved label encoder.\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_enc), y=y_train_enc)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# Keras model architecture (simple dense network)\n",
    "input_shape = X_train_pre.shape[1]\n",
    "keras_model = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "keras_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "keras_model.summary()\n",
    "\n",
    "# Train\n",
    "history = keras_model.fit(\n",
    "    X_train_pre, y_train_enc,\n",
    "    validation_split=0.1,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = keras_model.evaluate(X_test_pre, y_test_enc, verbose=0)\n",
    "yprob = keras_model.predict(X_test_pre)\n",
    "y_pred_keras = np.argmax(yprob, axis=1)\n",
    "f1m_keras = f1_score(y_test_enc, y_pred_keras, average='macro')\n",
    "print(\"Keras Test Accuracy:\", acc)\n",
    "print(\"Keras Test F1 (macro):\", f1m_keras)\n",
    "\n",
    "# Save Keras model in .keras (Keras v3 format) or SavedModel format\n",
    "keras_fp = os.path.join(MODELS_DIR, \"product_recommender_keras.keras\")\n",
    "save_keras_model(keras_model, keras_fp)\n",
    "\n",
    "# Save label encoder so we can map ints back to categories\n",
    "joblib.dump(le, os.path.join(MODELS_DIR, \"label_encoder.joblib\"))\n",
    "print(\"Saved label encoder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aea1b2",
   "metadata": {},
   "source": [
    "Compare model results & choose best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35ba8217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.218889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.196537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keras NN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  accuracy  f1_macro\n",
       "0              XGBoost  0.250000  0.218889\n",
       "1  Logistic Regression  0.208333  0.196537\n",
       "2        Random Forest  0.166667  0.125714\n",
       "3             Keras NN  0.125000  0.106667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model by F1-macro: XGBoost F1: 0.2188888888888889\n",
      "Best model file: C:/Users/awini/formative2-mlp/data/processed/models\\product_recommender_xgb.joblib\n"
     ]
    }
   ],
   "source": [
    "results = [rf_res, lr_res]\n",
    "if xgb_res:\n",
    "    results.append(xgb_res)\n",
    "# Keras result\n",
    "results.append({'name': 'Keras NN', 'accuracy': float(acc), 'f1_macro': float(f1m_keras)})\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(by='f1_macro', ascending=False).reset_index(drop=True)\n",
    "display(res_df)\n",
    "\n",
    "best = res_df.iloc[0]\n",
    "print(\"Best model by F1-macro:\", best['name'], \"F1:\", best['f1_macro'])\n",
    "\n",
    "# Map best model name to saved file\n",
    "model_map = {\n",
    "    'Random Forest': rf_fp,\n",
    "    'Logistic Regression': lr_fp,\n",
    "    'XGBoost': xgb_fp if HAS_XGB else None,\n",
    "    'Keras NN': keras_fp\n",
    "}\n",
    "best_model_fp = model_map.get(best['name'])\n",
    "print(\"Best model file:\", best_model_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5136f",
   "metadata": {},
   "source": [
    "Save a pointer to the best model for downstream integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baf79d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model info to C:/Users/awini/formative2-mlp/data/processed/models\\best_model_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_model_name': 'XGBoost',\n",
       " 'best_model_path': 'C:/Users/awini/formative2-mlp/data/processed/models\\\\product_recommender_xgb.joblib',\n",
       " 'label_encoder': 'C:/Users/awini/formative2-mlp/data/processed/models\\\\label_encoder.joblib'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save a small JSON/text pointer to the best model so integration scripts can load it\n",
    "import json\n",
    "out = {\n",
    "    'best_model_name': best['name'],\n",
    "    'best_model_path': str(best_model_fp),\n",
    "    'label_encoder': str(os.path.join(MODELS_DIR, \"label_encoder.joblib\"))\n",
    "}\n",
    "with open(os.path.join(MODELS_DIR, 'best_model_info.json'), 'w') as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print(\"Saved best model info to\", os.path.join(MODELS_DIR, 'best_model_info.json'))\n",
    "display(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
