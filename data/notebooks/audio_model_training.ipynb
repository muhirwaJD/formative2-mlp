{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80cd9ac-babc-421f-a181-ffa00543898c",
   "metadata": {},
   "source": [
    "#### Train the Model**\n",
    "\n",
    "We used a simple yet powerful Random Forest Classifier to identify speakers based on their voice features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60584b85-27ab-4061-9fb4-5d6f5251d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1993f-2bd8-47a1-8ae4-c3766b09eafd",
   "metadata": {},
   "source": [
    "#### **Load processed audio CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dc619d-1256-488a-801b-b9ddcd6b977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded data: 112 rows, 69 columns\n",
      " Audio features loaded successfully!\n",
      "                                      sample_id person  phrase  \\\n",
      "0      JD_Confirm_Transaction3.WAV.ogg_original     JD     NaN   \n",
      "1      JD_Confirm_Transaction3.WAV.ogg_pitch_up     JD     NaN   \n",
      "2  JD_Confirm_Transaction3.WAV.ogg_time_stretch     JD     NaN   \n",
      "3         JD_Confirm_Transaction3.WAV.ogg_noise     JD     NaN   \n",
      "4              JD_Yes_Approve3.WAV.ogg_original     JD     NaN   \n",
      "\n",
      "        augmentation  sample_rate  mfcc1_mean   mfcc1_std  mfcc1_min  \\\n",
      "0           Original        16000  -421.62290  117.957740 -603.38245   \n",
      "1     Pitch Shift +2        16000  -440.98620  127.579640 -647.51404   \n",
      "2  Time Stretch 1.1x        16000  -441.73760  123.142660 -648.08734   \n",
      "3   Background Noise        16000  -156.31702   44.884453 -239.05902   \n",
      "4           Original        16000  -449.03710  126.793560 -629.15845   \n",
      "\n",
      "   mfcc1_max  mfcc2_mean  ...  rolloff_min  rolloff_max  energy_mean  \\\n",
      "0 -231.42770  103.924740  ...     320.3125    6726.5625     0.036052   \n",
      "1 -267.67206  110.368110  ...     593.7500    6695.3125     0.023833   \n",
      "2 -263.59400  108.384445  ...     539.0625    6320.3125     0.024971   \n",
      "3  -65.33739   40.860107  ...    1367.1875    6937.5000     0.104073   \n",
      "4 -225.43637   87.081420  ...     335.9375    7070.3125     0.026453   \n",
      "\n",
      "   energy_std  energy_min  energy_max  zcr_mean   zcr_std  centroid_mean  \\\n",
      "0    0.042689    0.000168    0.164656  0.110226  0.091938    1417.507323   \n",
      "1    0.024899    0.000146    0.091180  0.103948  0.091256    1349.954815   \n",
      "2    0.029135    0.000156    0.113210  0.088906  0.072497    1321.044294   \n",
      "3    0.114229    0.009599    0.453914  0.292627  0.171823    2834.629791   \n",
      "4    0.036690    0.000121    0.134951  0.141988  0.113308    1744.690962   \n",
      "\n",
      "   centroid_std  \n",
      "0   1026.228634  \n",
      "1    884.412018  \n",
      "2    828.693536  \n",
      "3   1167.394101  \n",
      "4   1060.321195  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"../raw/audio_data/processed_audio_features.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\" Loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(\" Audio features loaded successfully!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7f55e-9036-4daf-9364-73436b13593f",
   "metadata": {},
   "source": [
    "#### **Fill missing 'person' from 'sample_id'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22825dc-0cb3-4aa9-9cf6-21fbac8a235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data after filling 'person': 112 rows\n"
     ]
    }
   ],
   "source": [
    "if df['person'].isna().all():\n",
    "    print(\" 'person' column empty. Extracting from 'sample_id'...\")\n",
    "    df['person'] = df['sample_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Drop rows with missing 'person'\n",
    "df = df.dropna(subset=['person'])\n",
    "print(f\" Data after filling 'person': {df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d2019-302e-493f-b006-8b436c558233",
   "metadata": {},
   "source": [
    "#### **Prepare features (X) and labels (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359b0d18-fae9-4b9b-a4c6-e77fe95999d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (112, 64)\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['sample_id', 'person', 'phrase', 'augmentation', 'sample_rate']\n",
    "X = df.drop(columns=[col for col in exclude_cols if col in df.columns])\n",
    "y = df['person']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(y.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71b6e1-da3b-4f9f-b429-4ed7bab91d30",
   "metadata": {},
   "source": [
    "#### **Split Data for Training and Testing**\n",
    "\n",
    "We divide the dataset into training (80%) and testing (20%). This helps evaluate how well your model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592b4409-db13-409f-aa41-b7d3892fdd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 89, Testing samples: 23\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c39ccb-dd09-4b86-8371-81e6fb8b75ee",
   "metadata": {},
   "source": [
    "#### **Train Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad0b6cd4-7bf0-4405-9859-f744cc8f1c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model training complete!\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=50,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\" Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86cef633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model training complete!\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\" Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8d09f-58aa-4e01-ae56-9c9cdb9b7b6e",
   "metadata": {},
   "source": [
    "#### **Evaluate on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21328d0e-26c9-49be-98f8-be7736d97412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          JD       1.00      1.00      1.00         4\n",
      "      Mariam       1.00      1.00      1.00        14\n",
      "      Noella       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0e008-d78a-4ae6-af54-876afda43585",
   "metadata": {},
   "source": [
    "### **Step 8: Save model and metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e533c9-f01f-4803-87d0-9288e7a1fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model and metadata saved in C:\\users\\LENOVO\\Documents\\formative2-mlp\\Audios\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = r\"../../models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(model, os.path.join(save_dir, 'audio_model.pkl'))\n",
    "joblib.dump(X.columns.tolist(), os.path.join(save_dir, 'feature_names.pkl'))\n",
    "joblib.dump(model.classes_, os.path.join(save_dir, 'class_names.pkl'))\n",
    "\n",
    "print(f\" Model and metadata saved in {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (.mlvenv)",
   "language": "python",
   "name": "mlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
